
# ğŸ½ï¸ YOLO Dish Detection Project

> ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºÑƒÑ…Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾ÑÑƒĞ´Ñ‹ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑÑ… Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ **YOLOv11**.  
> ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€: Ğ¾Ñ‚ Ğ²Ğ¸Ğ´ĞµĞ¾ â€” Ğ´Ğ¾ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸.

---

## ğŸ“¦ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°



```
yolo_dishes_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ ĞºĞ°Ğ´Ñ€Ñ‹ + ÑÑ‹Ñ€Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸
â”‚   â”œâ”€â”€ processed/        # Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â””â”€â”€ dataset/          # Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚ train/val/test
â”œâ”€â”€ notebooks/            # Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ figures/          # Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¸ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°
â”‚   â””â”€â”€ report.md         # Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
â”œâ”€â”€ runs/                 # ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ÑÑ Ultralytics-Ğ¾Ğ¼
â”œâ”€â”€ results/              # bounding box video
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ extract_frames.py
â”‚   â”‚   â”œâ”€â”€ augment.py
â”‚   â”‚   â””â”€â”€ split_dataset.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ infer_video.py
â”‚   â”‚   â””â”€â”€ dataset.yaml   # ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ´Ğ»Ñ YOLO
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ report/
â”‚   â”‚   â””â”€â”€ make_report.py
â”‚   â””â”€â”€ main.py            # orchestration CLI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

1.	<b>Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾</b>	Ğ’Ñ‹ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚Ğµ Ñ„Ğ°Ğ¹Ğ» data/raw/video.mp4	video.mp4
2.  <b>Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ ĞºĞ°Ğ´Ñ€Ñ‹</b>	<code>python -m src.data.extract_frames	data/raw/frames/*.jpg</code>
3.	<b>ĞĞ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ</b>	Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑŒ labelImg â†’ YOLO-txt	data/raw/labels/*.txt
4.	<b>ĞÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ</b>	<code>ppython -m src.data.augment</code>	data/processed/*.jpg + .txt
5.	<b>Ğ¡Ğ¿Ğ»Ğ¸Ñ‚</b>	<code>python -m src.data.split_dataset</code>	data/dataset/{train,val,test}/images,labels
6.	<b>Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°</b>	<code>python -m src.models.train</code>	runs/yolo11_exp*/weights/best.pt, ( Ñ‚Ğ°ĞºĞ¶Ğµ Ñ Ñ„Ğ»Ğ°Ğ³Ğ°Ğ¼Ğ¸:

<code>python -m src.models.train \
  --size s \
  --epochs 50 \
  --img 960 \
  --batch 8 \
  --lr0 0.005 </code>
 
<code>python -m src.models.train \
       --size x \
       --epochs 50 \
       --batch 32 \
       --lr0 0.005</code>)
7.	<b>ĞÑ†ĞµĞ½ĞºĞ°</b>	<code>python -m src.models.evaluate</code> (Ğ±ĞµÑ€ĞµÑ‚ ÑĞ°Ğ¼ÑƒÑ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ best.pt), Ğ»Ğ¸Ğ±Ğ¾ <code>python -m src.models.evaluate \
       --weights runs/exp11_s/weights/best.pt</code>	Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ metrics.json
8.	<b>Tuning Ã—2</b>	Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ¼ config.py, Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑĞµĞ¼ 7-8	3 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°
9.	<b>ĞÑ‚Ñ‡Ñ‘Ñ‚</b>	<code>python -m src.report.make_report</code>	report/report.md, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ report/figures
10. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞµĞ³Ğ¾ Ñ bounding box <code>python -m src.main infer</code>.
ĞœĞ¾Ğ¶Ğ½Ğ¾ Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸: <code>python -m src.main infer \
  --video data/raw/video.MOV \
  --weights runs/exp11_s/weights/best.pt \
  --out results/video_boxes.mp4 \
  --img 960 \
  --conf 0.3 \
  --batch 16</code>


## YOLOv11 Dish Detection Pipeline

### ĞšĞ°Ğº Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ

```bash
# 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
python -m venv venv && source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 2. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½
python -m src.main all --video /absolute/path/to/video.mp4
```

ĞŸĞ¾ÑĞ»Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğµ `report/` Ğ¿Ğ¾ÑĞ²Ğ¸Ñ‚ÑÑ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ `report.md` + Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸.
